import sounddevice as sd
import numpy as np
import speech_recognition as sr
import time
from datetime import datetime
import queue
import threading
import requests
import os
import face_recognition
import cv2
import pickle
from time import sleep

# è¨­å®š
SAMPLE_RATE = 16000
CHANNELS = 1
BLOCK_DURATION = 3  # ç§’
OUTPUT_TXT_FILE = "./" + datetime.now().strftime('%Y%m%d_%H_%M') + ".txt"
POST_URL = "https://96c6-125-103-211-238.ngrok-free.app/receive"  # ã‚µãƒ¼ãƒãƒ¼ã®URLï¼ˆé©å®œå¤‰æ›´ï¼‰
FACE_ENCODINGS_FILE = 'face_encodings.pkl'  # pickleä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«

# ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
DEBUG = True

def debug_print(message):
    if DEBUG:
        print(f"[DEBUG] {datetime.now().strftime('%H:%M:%S')} - {message}")

# éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã™ã‚‹ã‚­ãƒ¥ãƒ¼
q = queue.Queue()

# éŸ³å£°èªè­˜å™¨
recognizer = sr.Recognizer()

def save_face_encodings(known_folder, save_file=FACE_ENCODINGS_FILE):
    """
    æ—¢çŸ¥ã®é¡”ç”»åƒã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡ºã—ã¦pickleãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹
    """
    data = {}
    if not os.path.exists(known_folder):
        print(f"{known_folder} ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        return False
    
    for person_name in os.listdir(known_folder):
        person_dir = os.path.join(known_folder, person_name)
        if not os.path.isdir(person_dir):
            continue
        
        encodings = []
        for filename in os.listdir(person_dir):
            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
                image_path = os.path.join(person_dir, filename)
                try:
                    image = face_recognition.load_image_file(image_path)
                    face_encs = face_recognition.face_encodings(image)
                    encodings.extend(face_encs)
                except Exception as e:
                    print(f"ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼ {image_path}: {e}")
                    continue
        
        if encodings:
            data[person_name] = encodings
            print(f"{person_name} ã®é¡”ã‚’å­¦ç¿’ã—ã¾ã—ãŸï¼ˆ{len(encodings)} ä»¶ï¼‰ã€‚")
    
    if data:
        with open(save_file, 'wb') as f:
            pickle.dump(data, f)
        print(f"äººç‰©ã®é¡”ç‰¹å¾´é‡ã‚’ {save_file} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
        return True
    else:
        print("å­¦ç¿’å¯èƒ½ãªé¡”ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return False

def load_face_encodings(save_file=FACE_ENCODINGS_FILE):
    """
    pickleãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é¡”ç‰¹å¾´é‡ã‚’èª­ã¿è¾¼ã‚€
    """
    try:
        with open(save_file, 'rb') as f:
            return pickle.load(f)
    except FileNotFoundError:
        print(f"{save_file} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚é¡”ç‰¹å¾´é‡ã‚’å­¦ç¿’ã—ã¾ã™...")
        if save_face_encodings('known_faces'):
            with open(save_file, 'rb') as f:
                return pickle.load(f)
        return {}
    except Exception as e:
        print(f"ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return {}

def take_photo_from_usb_camera(filename='captured.jpg'):
    """
    USBã‚«ãƒ¡ãƒ©ã‚ˆã‚Šå†™çœŸã‚’å–å¾—ã™ã‚‹é–¢æ•°
    """
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    if not cap.isOpened():
        print("ã‚«ãƒ¡ãƒ©ãŒé–‹ã‘ã¾ã›ã‚“ã€‚USBã‚«ãƒ¡ãƒ©ãŒæ­£ã—ãæ¥ç¶šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return None
    debug_print("ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–ä¸­â€¦3ç§’å¾…æ©Ÿã—ã¾ã™ã€‚")
    sleep(3)
    debug_print("å†™çœŸã‚’æ’®å½±ã—ã¾ã™...")
    ret, frame = cap.read()
    if ret:
        cv2.imwrite(filename, frame)
        debug_print(f"{filename} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
        cap.release()
        return filename
    else:
        print("ç”»åƒã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        cap.release()
        return None

def recognize_person_from_encodings(unknown_image_path, tolerance=0.45):
    """
    pickleãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚“ã ç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¦é¡”èªè­˜å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹
    """
    debug_print("é¡”èªè­˜å‡¦ç†é–‹å§‹")
    
    # ä¿å­˜ã•ã‚ŒãŸç‰¹å¾´é‡ã‚’èª­ã¿è¾¼ã¿
    known_encodings_data = load_face_encodings()
    if not known_encodings_data:
        print("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None
    
    debug_print(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(known_encodings_data)} äºº")
    
    # æœªçŸ¥ã®ç”»åƒã‚’èª­ã¿è¾¼ã¿
    try:
        unknown_image = face_recognition.load_image_file(unknown_image_path)
        unknown_encodings = face_recognition.face_encodings(unknown_image)
        debug_print(f"æ’®å½±ç”»åƒã‹ã‚‰ {len(unknown_encodings)} å€‹ã®é¡”ã‚’æ¤œå‡º")
    except Exception as e:
        print(f"ç”»åƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    
    if not unknown_encodings:
        print("é¡”ã€å‡ºã¦ã“ã‚“ã ã£ãŸã«ã€‚")
        return None

    unknown_encoding = unknown_encodings[0]

    # å„äººç‰©ã®ç‰¹å¾´é‡ã¨æ¯”è¼ƒ
    for person_name, encodings in known_encodings_data.items():
        try:
            debug_print(f"{person_name} ã¨æ¯”è¼ƒä¸­...")
            results = face_recognition.compare_faces(encodings, unknown_encoding, tolerance=tolerance)
            if any(results):
                print(f"{person_name}ã•ã‚“ã€ãŠã¯ã‚ˆãƒ¼ã”ã–ã‚“ã™!('â—‡')ã‚")
                return person_name
        except Exception as e:
            print(f"é¡”èªè­˜æ¯”è¼ƒã‚¨ãƒ©ãƒ¼ {person_name}: {e}")
            continue

    print("ãŠã‚ã€ã ã‚Œã‘ã€œï¼Ÿ")
    return None

def send_message(person_name, status):
    """
    ã‚µãƒ¼ãƒãƒ¼ã«åå‰ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’POSTé€ä¿¡ã™ã‚‹
    """
    day = datetime.now().strftime('%Y-%m-%d')
    times = datetime.now().strftime('%H:%M')
    try:
        debug_print(f"ã‚µãƒ¼ãƒãƒ¼é€ä¿¡: {person_name} - {status}")
        res = requests.post(
            POST_URL,
            json={
                "æ—¥": day,
                "æ™‚é–“": times,
                "å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ": person_name,
                "status": status}
        )
        print("é€ä¿¡ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:", res.text)
    except Exception as e:
        print("é€ä¿¡å¤±æ•—:", e)

def detect_keyword_and_status(text):
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡ºã—ã¦ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¿”ã™
    """
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¾æ›¸ï¼ˆé¡ä¼¼è¡¨ç¾ã‚‚å«ã‚€ï¼‰
    keyword_patterns = {
        "å‡ºå‹¤": ["å‡ºå‹¤", "ã—ã‚…ã£ãã‚“", "å‡ºç¤¾", "ã—ã‚…ã£ã—ã‚ƒ", "ä»•äº‹", "ä¼šç¤¾", "ãŠã¯ã‚ˆã†"],
        "é€€å‹¤": ["é€€å‹¤", "ãŸã„ãã‚“", "å¸°ã‚‹", "ã‹ãˆã‚‹", "é€€ç¤¾", "ãŸã„ã—ã‚ƒ", "ãŠç–²ã‚Œ", "ã•ã‚ˆã†ãªã‚‰", "æœ€è¿‘", "ãƒ€ã‚¤ã‚­ãƒ³"],
        "ä¼‘æ†©é–‹å§‹": ["ä¼‘æ†©", "ãã‚…ã†ã‘ã„", "ä¼‘ã‚€", "ã‚„ã™ã‚€", "ã¡ã‚‡ã£ã¨"],
        "ä¼‘æ†©çµ‚äº†": ["æˆ»ã‚‹", "ã‚‚ã©ã‚‹", "å¾©å¸°", "ãµã£ã", "å†é–‹", "ã•ã„ã‹ã„"]
    }
    
    text_lower = text.lower()
    debug_print(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢å¯¾è±¡: '{text}'")
    
    for status, keywords in keyword_patterns.items():
        for keyword in keywords:
            if keyword in text or keyword in text_lower:
                debug_print(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º: '{keyword}' â†’ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status}")
                return status
    
    debug_print("è©²å½“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãªã—")
    return None

def recognize_from_queue():
    """
    éŸ³å£°èªè­˜ã‚’ã‚­ãƒ¥ãƒ¼ã‹ã‚‰å‡¦ç†ã™ã‚‹
    """
    debug_print("éŸ³å£°èªè­˜ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹")
    
    while True:
        audio_data = q.get()
        if audio_data is None:
            debug_print("éŸ³å£°èªè­˜ã‚¹ãƒ¬ãƒƒãƒ‰çµ‚äº†")
            break
            
        try:
            debug_print("éŸ³å£°èªè­˜å‡¦ç†é–‹å§‹")
            audio_bytes = (audio_data * 32767).astype(np.int16).tobytes()
            audio = sr.AudioData(audio_bytes, SAMPLE_RATE, 2)
            text = recognizer.recognize_google(audio, language="ja-JP")
            
            print(f"ğŸ¤ èªè­˜çµæœ: {text}")
            
            with open(OUTPUT_TXT_FILE, 'a', encoding='utf-8') as f:
                f.write(f"\n{datetime.now().strftime('%H:%M:%S')} - {text}")

            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º
            status = detect_keyword_and_status(text)
            
            if status:
                print(f"âœ… éŸ³å£°èªè­˜ã§ã€Œ{status}ã€ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚é¡”èªè­˜ã‚’é–‹å§‹ã—ã¾ã™...")
                
                # å†™çœŸæ’®å½±
                filename = take_photo_from_usb_camera()
                if filename:
                    # é¡”èªè­˜
                    person_name = recognize_person_from_encodings(filename)
                    if person_name:
                        # ã‚µãƒ¼ãƒãƒ¼é€ä¿¡
                        send_message(person_name, status)
                        print(f"âœ… {person_name}ã•ã‚“ã®{status}ã‚’è¨˜éŒ²ã—ã¾ã—ãŸï¼")
                    else:
                        print("âŒ é¡”èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                else:
                    print("âŒ å†™çœŸæ’®å½±ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            else:
                debug_print("å¯¾è±¡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ãªã„ãŸã‚ã€å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—")
                
        except sr.UnknownValueError:
            debug_print("éŸ³å£°ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        except sr.RequestError as e:
            print(f"âŒ Google APIã‚¨ãƒ©ãƒ¼: {e}")
        except Exception as e:
            print(f"âŒ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")

def realtime_textise():
    """
    éŸ³å£°èªè­˜ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å‡¦ç†ã™ã‚‹
    """
    debug_print("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜é–‹å§‹")
    
    with open(OUTPUT_TXT_FILE, 'w', encoding='utf-8') as f:
        DATE = datetime.now().strftime('%Y%m%d_%H:%M:%S')
        f.write("æ—¥æ™‚ : " + DATE + "\n")

    # éŸ³å£°èªè­˜ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹
    thread = threading.Thread(target=recognize_from_queue, daemon=True)
    thread.start()

    # éŒ²éŸ³é–‹å§‹
    try:
        with sd.InputStream(samplerate=SAMPLE_RATE,
                            channels=CHANNELS,
                            callback=audio_callback,
                            blocksize=int(SAMPLE_RATE * BLOCK_DURATION)):
            print("ğŸ™ï¸  ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•å®Œäº†ï¼")
            print("ğŸ“¢ ä»¥ä¸‹ã®ã‚ˆã†ã«ãŠè©±ã—ãã ã•ã„:")
            print("   - å‡ºå‹¤ã—ã¾ã™")
            print("   - é€€å‹¤ã—ã¾ã™") 
            print("   - ä¼‘æ†©ã—ã¾ã™")
            print("   - æˆ»ã‚Šã¾ã™")
            print("ğŸ’¡ Ctrl+Cã§çµ‚äº†")
            
            while True:
                time.sleep(0.1)
                
    except KeyboardInterrupt:
        print("\nğŸ›‘ çµ‚äº†ã—ã¾ã™...")
    finally:
        q.put(None)
        thread.join()

def audio_callback(indata, frames, time_info, status):
    """
    éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ¥ãƒ¼ã«æ ¼ç´ã™ã‚‹
    """
    if status:
        debug_print(f"éŒ²éŸ³ã‚¨ãƒ©ãƒ¼: {status}")
    q.put(indata.copy())

def initialize_face_recognition():
    """
    é¡”èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    """
    debug_print("é¡”èªè­˜ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–é–‹å§‹")
    
    # known_facesãƒ•ã‚©ãƒ«ãƒ€ã®ç¢ºèª
    if not os.path.exists('known_faces'):
        os.makedirs('known_faces')
        print("ğŸ“ known_facesãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¾ã—ãŸã€‚")
        print("ğŸ‘¤ ã“ã®ãƒ•ã‚©ãƒ«ãƒ€å†…ã«äººç‰©åã®ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã€ãã®ä¸­ã«é¡”å†™çœŸã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚")
        print("ğŸ“ ä¾‹: known_faces/ç”°ä¸­/photo1.jpg")
        return False
    
    # ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèªã¨ç”Ÿæˆ
    if not os.path.exists(FACE_ENCODINGS_FILE):
        print("ğŸ§  é¡”ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...")
        return save_face_encodings('known_faces')
    
    print("âœ… é¡”ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
    return True

def main():
    print("=" * 50)
    print("ğŸ¤– å‡ºé€€å‹¤ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  v2.0")
    print("=" * 50)
    
    # é¡”èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    if initialize_face_recognition():
        print("âœ… é¡”èªè­˜ã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã«åˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸã€‚")
    else:
        print("âš ï¸  é¡”èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        print("ğŸ“ known_facesãƒ•ã‚©ãƒ«ãƒ€ã«ç”»åƒã‚’é…ç½®ã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    
    realtime_textise()

if __name__ == '__main__':
    main()